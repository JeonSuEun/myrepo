L6 Processor Datapath and Control

Computer => Processor + Memory + Devices

Processor design(설계): Control(제어) + Datapath(데이터 경로)
Datapath에서 ALU design 사용
성능 측정 => 명령어의 수(Instruction count), Clock Cycle time, 명령어당 Clock cycle(CPI)
첫 단계는 프로그램의 요소지만, 두 번째 단계는 프로세서 구현을 기반으로합니다.
프로세서 설계 연구를 단순화하기 위해 MIPS 명령어의 하위 집합에 중점을 둠. => Memory: lw, sw / Arithmetic: add, sub, and, ori, slt / Branch: beq, j (이 정도 명령어로 만)

MIPS format(r,i,j) => 6~8page

Processor execution cycle
PC가 지정한 명령어를 메모리에서 가져온다 -> 하나 또는 두 개의 레지스터를 읽는다 -> ALU는 덧셈, 뺼셈등에 사용해야 한다. -> 결과는 메모리 또는 레지스터에 저장

***하나의 명령을 처리할때 lifecycle(데이터는 메모리와 기능 단위를 통해 흐름)
Fetch(Instruction) => 프로그램 저장소에서 명령을 얻음(주소는 레지스터의 PC에있는데 여기 주소를 메모리로 부터 읽음)
Decode(Instruction) => 읽어온 명령어의 크기와 요구행동 결정(읽어온 명령어가 무엇인지 해석)(Contro신호를 만듦)
Fetch(operand) => 피연산자 데이터 찾기 및 가져오기(연산자를 Fetch해옴)(Register 2개는 read하기 위한, 1개는 write하기 위한)
Execute => 결과 값 또는 상태 계산(ALU에서 실행)
Store(result)(write back) => 나중에 사용할 수 있도록 결과를 저장소에 보관(결과를 저장)(Data Memory에 저장 or Register File에 저장)
Next(Instruction) => 다음 명령어 결정(PC를 업데이트)

프로세서 구현: 논리 회로(logic circuit)
조합 회로(Combinational circuit): 현재 입력으로만 출력 결정 (ALU)
순차 회로(Sequential circuit): 현재 입력과 이전 상태로 출력 결정 (Register)

Clocking
동일한 clock edge로 clock된 모든 저장 요소
edge 트리거 clocking(상승 또는 하강 clock edge) / 클록 사이클당 하나의 클록 주기 / 클록이 "충분히 느리면" 설계는 항상 작동

Single cycle design => 연산을 한 cycle에서 다 함
Multi cycle design => Combinational logic을 쪼개서 중간에 storage element를 넣어 다른 cycle에 각각~

Storage element: Register File
레지스터 파일은 32개의 레지스터로 구성됨 
2개의 32비트 출력은 Read 데이터1 과 Read 데이터2로 이루어짐 / 1개의 32비트 입력은 Write데이터(CLK신호필요(뭘 저장, 어떤시점에~))로 이루어짐
Read register1은 Read data1에 넣을 레지스터를 선택(2도 마찬가지)
Write register는 RegWrite = 1일 때 Write Data를 통해 쓸 레지스터를 선택
RegWrite => 0 or 1이냐에 따라서 read data or write data로 구분됨
Clock input(CLK) => Write 작업은 CLK입력과 동기적으로 수행됨

Storage element: Memory
1개의 출력은 Read data / 1개의 입력은 Wirte data
주소 => MemRead = 1일 때 Data Out에 넣을 단어를 선택.(1이면 Read data) / MemWrite = 1일 때 Data In을 통해 쓸 단어를 선택(1이면 Write data)
Clock input(CLK) => write작업에만 사용되는 요소. 읽는동안 조합 논리 블록으로 동작.(유효한 주소 -> "접속 시간(access time)"이후 유효한 데이터 출력, 현실을 약간 단순화함)

Instruction Fetch(IF) unit
Operations => Fetch Instruction: Inst. <- mem[PC];(메모리의 프로그램 카운터에서 읽어 inst.에 저장) / Update program counter: PC <- PC + 4;(다음 주소 계산)

Execution (EX) unit
Operations => Arithmetic & logic, Load/Store, Branch Instructions / Control 신호 2개(RegWrite, ALU operation(MUX select 신호 필요))

Add RTL(R-format)
add rd, rs, rt => inst. <- mem[PC];(instruction Fetch(공통단계)), R[rd] <= R[rs] + R[rt];, PC <- PC + 4(업데이트)

Sub RTL(R-format)
Sub rd, rs, rt => inst. <- mem[PC];, R[rd] <- R[rs] - R[rt]; PC <- PC + 4

Datapath: Reg/Reg operations
R[rd] <- R[rs] op R[rt];
디코딩된 명령어를 기반으로 한 ALU 제어 및 RegWrite / 레지스터1, 레지스터2 및 rs,rt,rd 필드에서 레지스터 쓰기
RegWrite=1 => 연산된 결과가 저장 / ALU 4 => 2^4

OR immediate instruction(I-format)
ori rt, rs, imm => inst. <- mem[PC]; / R[rt] <- R[rs] OR ZeroExt(imm);(상위 16bit를 0으로 채운다, imm => 16bit / 총 32bit) / PC <- PC + 4;

Datapath: immediate operations
2개의 Mux와 1개의 ZeroExt가 추가됨. 첫 번째 MUX: RegDst에 의해 R 형식인 경우 Rd를 선택함. 두 번째 MUX: ALUsrc에 의해 R 형식인 경우 레지스터에서 데이터를 선택함
Mux를 둬서 rt와 rd중 선택되게(format에 따라)(목적지 레지스터 정하는거!) R-format이면 rd, I-format이면 rs / RegDst=1 : rd, RegDst=0 : rt 
ALUsrc=0 : R[rt] 출력, ALUsrc=1 : ZeroExt출력

Load RTL
lw rt, rs, imm16 => inst. <- mem[PC];, Addr <- R[rs] + SignExt(imm16);(메모리 주소 계산), R[rt] <- mem[Addr];(레지스터에 데이터 로드), PC <- PC + 4;

Datapath: Load 
Sign extension logic이 추가됨 / MemtoReg = 1: Read data가 ~

Store RTL
sw rt, rs, imm16 => inst. <- mem[PC];, Addr <-R[rs] + SignExt(imm 16);, mem[Addr] <- R[rt];(데이터를 메모리에 저장), PC <- PC + 4;

Datapath: Store
레지스터에서 메모리까지의 경로가 생성됨(Read data2(R[rt]) -> Write data(rt레지스터값))

Branch RTL
beq rt, rs, imm16 => inst. <- mem[PC];, Cond(zero flag) <- R[rs] - R[rt];, 
if (Cond ==0) then PC <- PC + 4 + (SignExt(imm16) << 2);(Branch if equal)(새로운 주소를 만듦)
else PC <- PC + 4;(Fall through otherwise)
즉, rs == rt 이면 if문 실행

Datapath: Branch  
instruction fetching을 위한 다음 주소 계산
ALU => MUX 사용 : 1이면 branch, 0이면 Fall th~ / Branch target(새로운 address를 계산하는 파트)

The next address

PC는 명령어 메모리에 바이트 주소가 지정됨
순차: PC[31:0] = PC[31:0] + 4(100)(0, 2bit은 고정되어 있으니 PC계산할 때 30bit만사용)
Branch operation(Relative addressing): PC[31:0] = PC[31:0] + 4 + SignExt(imm) * 4

명령어 주소 => PC는 바이트 주소로 지정되지만 명령어 길이는 4바이트임 / 그러므로 32비트 pc의 2LSB는 항상 0임
하드웨어가 2개의 LSB를 유지하도록 할 이유 X -> 그러므로 30BIT만 사용 순차: PC[31:2] = PC[31:2] + 1, Branch: PC[31:2] = PC[31:2] + 1 + SignExt(imm)

Datapath: Next instruction logic
PC는 정상적으로 다음 명령어로 증가됨
add immediate* 4 to PC+4 / LSB 2bit=>0(실제계산에서 상위 30bit만!) / Branch condition(zero status flag)

jump RTL(pseudo direct addressing)
j target => inst. <- mem[PC];, PC[31:2] <- {PC[31:28], target[25:0]}(다음 주소 계산)

Datapath: IFU with jump
PC가 pseudo direct jump인지 MUX가 제어함(jump이면 앞 MUX로부터 나오는 값 안쓰고 jump값 씀)(새로운 주소값 => MUX사용!)

Adding control
데이터 경로조각에 대한 제어 지점 식별: Instruction fetch unit, Integer function unit, Memory
제어 신호 유형 분류: 멀티플렉서를 통한 데이터 흐름, 상태 정보 쓰기
각 명령어에 대한 제어 신호 도출
위 3개를 모두 하나에 넣기!

***이해 하는게 중요
Single-cycle datapath 
처음부터 끝까지 한 사이클에 전부!
control signals: RegDst, RegWrite, ALUSrc, ALUOp, MemWrite, MemRead, MemtoReg, PCSrc(다음 PC를 사용할지, 계산된 주소를 사용할지 선택)

R-format instruction dataflow
RegDst=1, RegWrite=1, ALUSrc=0, ALUOp, MemWrite=0, MemRead=0, MemtoReg=0, PCSrc=0

I-format load instruction dataflow
RegDst=0, RegWrite=1, ALUSrc=1, ALUOp, MemWrite=0, MemRead=1, MemtoReg=1, PCSrc=0

I-format store instruction dataflow
RegDst x, RegWrite=0, ALUSrc=1, ALUOp, MemWrite=1, MemRead=0, MemtoReg x, PCSrc=0

I-format branch instruction dataflow
RegDst x, RegWrite=0, ALUSrc=0, ALUOp, MemWrite=0, MemRead=0, MemtoReg x, PCSrc zero

***j-format jump instruction dataflow(sueudo direct addressing)
RegDst x, RegWrite=0, ALUSrc x, ALUOp x, MemWrite=0, MemRead=0, MemtoReg x, PCSrc x, jump=1

기타제어신호
ExtOp => 1: signed extension, 0: unsigned extension
Branch => PCSrc 신호 제어 / PCSrc = Branch o Zero / 조건 branch 명령이 실행되면 1로 실행되고 그 외는 0

Single-cycle Processor
CPI=1인 디자인 / 장점: 굉장히 단순하다 / 
단점: 다양한 명령어에 소요되는 시간이 다르기 때문에 메모리 및 기능 단위의 비효율적 활용(ALU는 짧은 시간동안만 값을 계산함)
, 사이클타임은 long cycle time일때 최악의 경로이다(PC update time+,instruction memory read time+, register file read time+, ALU delay+,data memory read time+,register file write time등)

***단점 완화
Multi-cycle 구현
각각의 명령어를 여러스텝으로 나눔, 각 스탭은 1사이클씩, 명령어마다 다른 CPI (레지스터를 사용하여 각 단계를 분리함(storage element를 추가해서 single->multi))

Multi-cycle design 장단점
장점: 짧은 cycle time(높은 clock frequency), 단순명령어를 빨리 끝낼수있다., 기능 단위는 하나의 명령에 두번 이상 사용 할 수 있다(파이프라이닝)(프로세서 구현에 필요한 하드웨어 감소)(Throughput 증가)
단점: 복잡함, 레지스터를 추가해야함

Multi-cycle big picture
레지스터로 구분된 일련의 조합 논리 블록으로 데이터 경로를 구성(레지스터로 Datapath를 쪼갬)
데이터가 레지스터에서 다음 레지스터로 이동함에 따라 각 1클럭 주기 길이의 일련의 단계로 명령어를 구현
일련의 상태로 제어를 구현(마이크로코드로 프로그래밍 가능)

Multi-cycle divisions
데이터 경로를 각각 1클럭 주기의 단계로 나눔. 명령어 범위는 MIPS Multicycle design에서 3~5단계. 명령어의 수명 주기를 기억
***PC -> Instruction memory(IF(instruction fetch)) -> Registers(RF(register fetch + decode)) -> ALU(EX(execute)) -> Data memory(MEM(memory access)) -> Registers(WB(write back))

Multi-cycle vs Single-cycle
Multi => 레지스터 포함 / (레지스터에)임시적인 데이터 저장 / 컨트롤과 관련된 state관리

Timing methodology
명령어 기능에는 multiple clock이 필요함 / 클록 주기에 사용되는 데이터는 안정적이어야 함(데이터는 등록된 값, 등록된입력이 있는 조합 논리로 구동가능)
레지스터를 추가할수록 frequency증가(clock cycle time 감소) but 성능 보장 x

Control Signals
제어 신호는 더 이상 디코딩된 명령에 대해서만 결정되지 않음(시퀀싱에 사용되는 유한 상태 머신(현재 정보 세트, 현재 출력은 이전 상태 및 입력에 의해 결정))
FSM => 1.Mealy: 이전 상태와 입력으로 출력 2.Moore: 이전 상태만 이용해서 출력

High-level control flow
모든 명령어를 fetch/decode하는 공통 2클록 시퀀스
특정 유형의 명령을 실행하기 위한 1~3개 클록의 개별 시퀀스

CPI of the multi-cycle implementation
EX-> Clock cycles 수 : Loads: 5, Stores: 4, R-format instructions: 4, Branches: 3, Jumps: 3 / Instruction mix : 22% loads, 11% stores, 49% R-format instructions, 16% branches, and 2% jumps
CPI = 0.22 * 5 + 0.11 * 4 + 0.49 * 4 + 0.16 * 3 + 0.02 * 3 = 4.04

PLA implementation(63PAGE)

Microprogramming
제어 FSM을 구현하기 위한 대체 방법 => 현재 출력 및 상태 선택을 이전 상태(마이크로 프로그램 카운터)에 의해 주소 지정된 메모리(제어 저장소)의 마이크로 명령어로 나타냄
상태 시퀀싱은 다양한 형태 가능 => 카운터,마이크로 명령어에 완전히 지정된 점프 대상, 조건부 분기/점프, 다중 방향 분기 테스트 / 소프트웨어와 데이터 경로 하드웨어 간의 추상화 수준을 제공

Microprogramming tradeoffs
장점: 유연함(바꿀수있음), 강력한 명령어 세트 구현 가능(복잡한 명령을 간단하게 구현 가능), 동일한 시스템에서 여러 ISA를 구현할 수 있음(호환성)
단점: 비싸고 느리다

요약 
프로세서 설계에는 동작사양에서 물리적 구현까지 데이터 경로 및 제어의 개선이 필요. 
Single-cycle 단점 => 긴 주기 시간, 거의 모든 명령에 비해 길다, 불필요하게 중복된 리소스로 인한 비효율적인 하드웨어 활용
Multiple-cycle => 실행을 비슷한 기간의 작은 단계로 분할. 각 단계를 한 주기로 처리
제어 구현의 세 가지 일반적인 형태 => Digital logic / PLA / Microcode




CH L7-Enhancing performance with Pipelining
Pipelining => 실행 시 여러 명령이 겹쳐지는 구현 기술
장점: 기능 유닛의 활용도가 더욱 향상, 명령어 처리량 측면에서 성능을 획기적으로 향상(Throughput 증가, N개로 쪼개면 N개가능 Throughput N배(이상적))
단점: 하드웨어 요구사항 증가, 여러 유형의 "Hazard"조건

Sequential processing => 현재 작업 세트가 완료된 후에만 새 작업 세트가 시작됨

Pipelined processing => 현재 작업 세트의 첫 번째 작업이 완료되면 새 작업 세트가 시작됨

Pipleline divisions
데이터 경로를 각 1주기의 단계로 나눔. 명령어의 범위는 MIPS 파이프라인에서 3~5단계

Pipelining load
각 단계마다 5개의 독립적인 기능 유닛이 작동(레지스터 파일을 제외하고 각 기능 단위는 한 번만 사용)
첫 단계가 IF 단계를 완료하자마자 다른 로드가 시작될 수 있음. 각 로드를 완료하는 데 여전히 5사이클 소요
***그러나 처리량이 훨씬 높아짐!!(하드웨어는 그대로 존재하기 때문에 가능)
Load IF(1cycle), RF/ID(2cycle), EX(3cycle), MEM(4cycle), WB(5cycle)
ILP => Instruction, Level, Parallelision?(병렬)
매 사이클마다 하나의 명령어가 파이프라인에 들어감(효율적인 CPI는 1)
But 파이프라이닝 stage를 무한으로 늘릴수 없다(해저드떄문)

만약 Register file read/write : 100 ps / ALU operation: 200 ps / Memory access: 200 ps => load => 800ps  but Pipelined사용하면 4배 빠른 200ps
Stage5에서 해저드 뒤에 따라오는 명령어가 사용하는부분을 사용함 => 충돌 발생
로드 명령어가 WB 단계에 도달하면 다른 명령어가 IF/ID 단계를 차지함

Pipeline control
single-cycle과 달리 단일 명령으로 모든 제어 라인을 설정하는 방법을 결정하지 않습니다. 
RF/ID 단계에서 신호를 생성하기 위해 메인 제어 장치를 사용함 => 컨트롤 복잡
*** 최종적으로 Throughput 향상

***Hazards(이상적인 Throughput x인 이유)
1.Structural Hazard(구조적 해저드): 하나의 리소스에 동시에 2개의 명령어가 접근할때
ex-> load: 5clock cycle, add: 4clock cycle 이면 load가 write back 단계에 들어갈때 한 사이클은 늦은 add 명령어도 write back 단계! => 해저드 =

2.Data Hazard(데이터 해저드) 
명령은 아직 파이프라인에 있는 명령의 결과에 따라 달라짐
ex-> A=B+C / D=A+E => 동시에 실행X(읽고쓰는거 동시X)(Data dependence) / 해결1:딜레이시키기(첫번째 A가 writeback될때까지 기다려야함) , 해결2:read와 write 동시에 할 수 있는 레지스터 제공

3.Control Hazard(컨트롤 해저드)
컨트롤 결정은 Branch 명령이 PC를 변경하는 경우와 같이 실행 경로를 결정
ex-> if(A=B) print C else print D / 참인지 결정되는 순간은 execute 단계에서 ALU를 통해 A-B의 연산결과와 ZERO~를  이용해 / Instruction patch/decode 상태 => A==B의 조건의 결과에 맞지않는 반대조건의 명령어로 가득차있음 => 오버헤드

Structural Hazard => 하드웨어 리소스 자원의 충돌로발생
기능 단위가 완전히 파이프라인되지 않은 경우 종종 발생, 기능단위는 명령어당 한 번만 사용 가능, 각 기능단위는 모든 명령에 대해 동일한 단계에서 사용되어야함
해결방법1: 뒤 따라오는 명령어를 쉬게함(전체 Throughput성능에 영향x)(가장 단순한 해결) / 해결방법2: 하드웨어 설계를 변형(어려움)

Data hazards(data dependencies가 있을때(특정한 데이터에 대해 두 명령어가 의존성이 있는 경우))
파이프라인이 피연산자에 대한 읽기/쓰기 액세스 순서를 변경하여 명령을 순차적으로 실행 할 때와 순서가 다를 때 발생
ex-> ADD $1(저장되는 시점이 writeback 단계), $2, $3 / SUB $4, $1(Instruction decode단계 => 준비가 되지 않은 데이터를 읽어들임 => 두번째 명령어의 실행이 지연됨)(Data Hazard), $5

Data dependency types
1.RAW(True): write한 후 read (A=B+C, D=A+E)
2.WAR(Anti): Read한 후 write => 순서가 맞으니 Data hazards 원인 x
3.WAW(Output): write한 후 write => write는 write back에 한정되므로 data hazards 원인 X
4.Rar(Input): Read한 후 read => 두번 read => Data hazards와 관계 x

Data hazards 해결법
1.Stalls => 뒤 따라오는 명령어를 쉬게함(빈번하게 하면 안됨(성능 저하))
2.Change clock cycle => 전체 clock cycle을 반으로 나눠 실행
3.Forward or bypassing => ALU의 계산겨로가를 writeBack하기전에 다음명령어로 미리 전달
4.Restrict software => compiler에서 instruction 스케듈링을 통해 Data hazard가 발생하는 명령어의 sequences를 제거해주는 방식(한계 있음)

Stalls 성능 효과
이상적인 cpi =1 ,3clock 지연, 지연이 명령의 40%인경우 ? => new effective CPI = 1 + 3*0.4 = 2.2 (throughput이 반 이상 나빠짐)

register file(동시에 가능하도록 설계) 성능 효과
이상적인 cpi =1 ,2clock 지연, 지연이 명령의 40%인경우 ? => new effective CPI = 1 + 2*0.4 = 1.8

Forward 성능 효과
*** 미리 전달 / Forwarding unit(하드웨어 필요) / 많은 RAW해저드 해결하는데 유용
이상적인 cpi =1 , 지연이 명령의 40%인경우 ? => new effective CPI = 1

Forwarding의 한계
그러나 모든 데이터 해저드를 해결X => 해결법: 값을 전달할 수 있을 때까지 파이프라인을 정지

Hazard detection unit => hazard가 발생했는지
PC및 IF/ID 레지스터의 쓰기와 실제 제어 값과 모두 0 사이를 선택하는 멀티플렉서를 제어

Compilers(마지막 방법) => 명령어의 순서를 조금씩 바꿔주기
이러한 해저드 중 일부를 제거하기 위해 컴파일러를 제한할 수 있지만 이러한 해저드는 자주 발생하므로 하드웨어에서 문제를 해결하는 것이 합리적(ex->대상에 의존하지 않는 것으로 로드 지연 슬롯을 채움)
여전히 세밀하게 조정된 최적화를 위해서는 컴파일러가 지연 동작을 고려해야 함(파이프라인 스케쥴링 또는 명령어 스케쥴링은 컴파일러가 지연을 방지하기 위해 명령어를 재배열하는 기술)

Control hazard(if,for) => 피할수없다
branch와 같은 제어 종속성으로 인해 발생 / 만약 브런치가 이루어지지 않으면 PC+4로 제어가 계속됨 / 브런치가 이루어지면 제어가 변경되고 PC는 새 주소를 나타냄(***MEM단계까지는 해당 지점을 가져올지 여부를 알 수 없음)
데이터 해저드보다 더 큰 성능 문제를 일으킴 / taken => 새로운 주소를 만들어 branch(taken이면 하고 있는데 파이프라인을 flush(비워내다)=> control hazard)

Branch stall
branch만나면 뒤 3개의 stage동안 정지해야함
이상적인 cpi =1 ,지연이 명령의 30%인경우 ? => new effective cpi = 1 + 3 * 0.3 = 1.9

Control hazard
1.stall => 브런치 결과가 결정될 때까지 순차적으로 작동하고 새 명령 가져오기를 일시 중지함
2.predict taken or not-taken(일반적인 해결책) => 브런치 여부를 예측하고 경로를 따라간다. 예측이 틀려도 추가 패널티가 없는지 확인.(예측이 틀리면 flush)
3.Scheduling branch delay slot => branch 지연 슬롯을 채워 결과가 해결될 때까지 제어를 포함하지 않는 작업을 수행.(MIPS Processor에서 사용하는 해결책)

Reduced Branch penalty
ALU 대신 별도의 비교기를 사용하고 브런치결정을 ID/RF로 이동할 수 있음(패널티를 1사이클로 감소)(원래 MEM stage에서 판단하는걸 1stage땡김)(단순 브런치와 복잡한 브런치에 대해 브런치 결정을 다르게 평가)(하드웨어 예측 사용)
브런치 예측 방식 => Predict-not-taken / Predict-taken / ***Dynamic branch prediction (히스토리 기반으로)

***Dynamic branch prediction => 과거의 행동에 기반함
브런치 동작 테이블을 유지하고 예측을 위해 조회
Branch prediction buffer(or branch history table)(저장하는 공간)
1비트 값의 PC주소 인덱스 테이블의 LSB(Branch의 PC값) / 지난번에 브런치를 수행했는지 여부를 나타냄 / 실제 브런치상태를 평가하고 잘못된 부분을 수정(파이프라인을 플러시하고 가져오기를 다시 시작하여 복구)(예측 리셋)
일반적으로 2bit사용 / 리소스 오버 헤드 관점에선 1bit가 나음

1-bit prediction
predict taken ->(not taken) predict not-taken / predict not-taken ->(taken)predict taken 
한번에의해 상태가 바뀜

2-bit prediction 
바로 상태가 안바뀜 두번 해야 바뀜 "00" => strongly taken "01" => weakly taken "10" => weakly not taken "11" => strongly not taken

1-bit vs 2-bit(70page)
2비트 히스토리를 사용한 브런치 예측이 훨씬 더 정확

Advanced pipelining
파이프라이닝은 명령어를 겹쳐서 ILP(명령 수준 병렬성)를 활용
제한: 애플리케이션 병렬성의 고유한 측면, 병렬성을 드러내는 컴파일러 기술, 중복된 명령을 처리하는 기능 단위 기능, 병렬로 실행될 수 있는 명령어를 찾는 하드웨어 능력
ILP 활용은 아키텍처와 컴파일러를 모두 포함하는 다양한 접근 방식을 사용하는 활발한 연구 분야.

Exploiting ILP: Superpipelining(ILP를 높이는 1번째 방법)
스테이지를 잘게 쪼갬(더 높은 클록 주파수를 목표로 함, 더 많은 레지스터, 더 복잡한 해저드문제)

Exploiting ILP: Superscalar => 동시에 2개이상 명령어
하드웨어가 더 복잡해짐
충분한 명령어가 공급되면 충분한 성능향상

Loop Unrolling => 컴파일러 최적화 기법
동시에 더 많이!

Dynamically scheduled pipeline => Data defendencies 없다고 판단되면 순서없이 먼저 사용

muliti-issue의 한계
동적으로 예약할 수 있는 명령어 부족 / 병렬 실행을 위한 기능 단위 복제 / 파일과 메모리를 등록하기 위한 포트를 늘림 / 디코딩 문제와 클럭 속도 및 파이프라인 깊이에 미치는 영향

Summary
파이프라이닝은 대기 시간을 개선하지 않지만 처리량을 개선함
파이프라이닝은 ILP를 활용함
성능향상은 프로그래머에게 보이지 않음(속도 향상은 파이프라인 깊이와 동일)
구조적 해저드: 더 많은 하드웨어 리소스 필요
데이터 헤저드: forwarding필요, 컴파일러 스케듈링 필요
컨트롤 해저드: 조기 평가, 지연된 브런치, 예측
파이프라인 길이가 늘어나면 해저드가 증가하고 대기 시간이 늘어남
컴파일러는 데이터 비용을 줄이고 해저드를 제어할 수 있음






CH-L8 Exploiting Memory Hierarchy

프로세서(CPU) 프로세스(실행중인 프로그램)
(Register file, cache(SRAM), Main memory(DRAM), SSD(Flush memory), Disk storage)

Memory system => 명령어와 데이터를 위한 저장 구성요소, 메모리 계층구조 사용,
I/O 컨트롤 인터페이스 제공 => 
1.port-mapped I/O(Intel)(프로세서상에 입출력 포트추가)(단점:프로세서 증가(핀 추가)) 
2.Memory-mapped I/O(ARM,...)(메모리주소공간에서 일부 영역을 입출력장치 주소 할당)(단점: 특정영역을 명령어나 데이터를 저장하는 용도로 못씀)

Memory hierarchy
CPU registers(속도 가장 빠름) - Cache memory - Main memory - Storage device(속도 가장 낮음)

DRAM 내부 아키텍처
프로세서의 메모리 컨트롤러에 의해 관리됨. 메모리 모듈은 여러 DRAM칩을 구성되고 DRAM칩은 여러 뱅크로 구성됨 (SIMM(한면), DIMM(양면))
DRAM 뱅크는 여러 하위 어레이로 구성되며 하위 어레이에는 셀 어레이(즉,매트)가 포함됨(chip->bank->subarray->mat)
각 비트셀은 하나의 비트 값을 저장함 / 감지 증폭기는 비트라인의 전압 레벨을 높여 값을 읽음
커패시터에 전하로 저장된 데이터 => 주기적으로 새로 고쳐야함. 즉, 휘발성(전원꺼지면 저장x)

non-volatile => ReRAH, PCRAM, STT-MRAM

Flash storage
비휘발성 반도체 저장 / 디스크보다 100배~1000배 빠름 디스크보다 더 작고, 더 낮은 전력, 더 견고함. 하지만 $/GB(디스크와 DRAM간)가 더 높다.
수명: 100,000/프로그램/삭제 주기(DRAM: 10^16) / 데이터 유지시간: 10년   (FTL(Flash Translation Layer)지원)

Disk Storage
비휘발성, 회전 자기 저장 장치

SRAM(크기크면 속도 더 빠름) / DRAM(가격이 더 쌈)
이상적: SRAM의 액세스 시간 + 디스크의 용량 및 비용/GB

*****Principle of Locality(메모리 계층을 사용할 수 있는 이유)
프로그램들이 특정한 시간에 전체주소공간에서 아주 일부의 영역에만 접근한다
Temporal Locality(시간적 지역성) => 시간적으로 한번접근 한 것을 또 접근 ex-> for문의 i계속 접근
Spatial Locality(공간적 지역성) => 인접한 주소 접근 ex-> array[0],array[1]... 접근

Taking Advantage of Locality
메모리계층구조 => 다양한 메모리들을 계층적으로 쌓아
모든 것을 디스크에 저장하고 일부 항목을 상위 메모리에 캐시
최근에 액세스한 항목을 디스크에서 더 작은 DRAM 메모리로 복사
최근에 액세스한(그리고 근처에 있는) 항목을 DRAM에서 더 작은 SRAM 메모리로 복사

Memory Hierarchy Levels
Block단위로 복사
Hit(내가 원하는 데이터가 상위메모리에 존재) Hit ratio: hits/accesses
Miss(상위메모리에 내가원하는 데이터 존재x => 하위에서 복사해옴) / Time taken: miss penalty / Miss ratio: misses/accesses = 1 - hit ratio

Memory Organization
가장 간단한 것은 한 번에 하나의 프로그램만 찾아서 메모리에 로드하는 유니프로그래밍 모델

유니프로그래밍 문제
1. 프로그램은 운영 체제를 쉽게 파괴할 수 있다.(OS와의 침범)
***2. 여러 애플리케이션을 실행하는 것은 불가능하다
해결책은 서로 다른 애플리케이션, 즉 프로세스 간에 메모리를 투명하게 공유하는 것(여러 프로세스가 하나의 주 메모리에 공존해야 함. 메모리 구성은 프로세스에 투명해야 함. 실행 중인 프로세스 수에 제한이 없음.
프로세스는 다른 프로세스에 영향을 주지 않고 물리적 메모리의 어느 곳에나 배치할 수 있음)

Multiprogramming model
여러 애플리케이션이 메모리에 로드되도록 허용. 여러 애플리케이션이 동일한 메모리를 사용할 수 있음.
문제:여전히 OS를 재정의하는 데 문제가 있음. 프로그램은 서로 덮어쓸수도 있음.(서로 침범 / 메모리등분 => 멀티X(Virtual memory로 해결))

Virtual Memory(OS에서 제공, 모든 프로세스마다 최대한의 메모리(주소의 비트수가 최대 메모리 ex-> 32bit => 2^32))
주 메모리를 보조 저장시의 "캐시"로 사용(CPU 하드웨어와 운영체제(OS)가 공동으로 관리)
프로그램은 주 메모리를 공유함(DRAM)(각각에는 코드와 데이터를 위한 개인 가상 주소 공간이 있음)(다른 프로그램으로부터 보호됨)
CPU와 OS는 가상 주소를 물리적 주소로 변환함(VM "Block"은 page라 불리고, VM translation "miss"는 page fault라 불림)
가상주소는 ISA에 의해 결정 / 물리적 주소는 DRAM에 의해 결정

Disk storage -> physical Memory (page로 복사) 
physical memory -> Processor L2 ccache (block으로 복사)

Using Virtual Addresses
***프로그램을 메모리의 어느 위치에나 로드할 수 있으므로 재배치(한 프로그램의 주소를 쉽게 바꿔줌)가 간단, 컴파일된 애플리케이션을 원하는 수만큼 동시에 로드
물리적 주소를 사용해 메모리에 액세스 / 주소변환(virtual과 physical 사이의 변환필요)을 통해 여러 프로세스가 메모리를 공유할 수 있음(프로세스는 메모리 주소 공간과 프로세서 상태의 조합으로 생각가능)

Address Translation
하드웨어에서 가상 주소를 물리적 주소로 변환(모든 메모리액세스에서 변환이 동적으로 발생해야 함. 이제 각 애플리케이션에는 자체 주소 공간이 있음.)(MMU(메모리 관리 장치)가 이 기능을 제공)
CPU - MMU(변환역할,cpu안에들어있음,pagetable참고) - physical Memory   => 이 개념 덕에 여러 프로글매 동시 실행가능

main memory의 효율적인 사용
블록 사이즈를 4KB로 통일 => 파편화 최소! / Virtual -> physical Memory (PAGE단위로!복사)

Paging => 메모리 파편화를 줄이는 방법
메모리를 페이지라고 알려진 더 작고 고정된 크기로 나누는 방법
페이지 테이블(각 프로세스 페이지의 기본 주소를 제공)
변환과정은 단순(페이지 테이블에서 페이지번호를 조회(주 메모리의 물리적 주소 반환))(페이지 오프셋은 페이지의 특정 바이트에 액세스하는 데 사용) => address를 만듬!
VA: P(page number) -> 10칸 => 2^10 = 1024 = page개수 /  O(page offset) -> 10칸 => 10bit => 2^10 => 1KB의 page사이즈
page의 사이즈는 바뀌면 안됨(offset크기는 고정)
물리적 메모리는 동일한 크기의 프레임으로 나눔(페이지 사이즈 = 프레임 사이즈) frame => physical에서 사용되는 용어 / frame number = page number / frame offset = page offset

Paging Address Translation(V -> P)
Fixed-size pages
없으면 page fault => Disk에 간 데이터를 physical로 올려줌(Virtual을 통해)(page테이블에서함)(SWAP)
V 31 ~ 12 => page number / 11 ~ 0 => page offset  4KB    (ex)
P 29 ~ 12 => page number / 11 ~ 0 => page offset  4KB   => 이거 조차 오버헤드나면 또 Caching 
***위 두개 변환할때 MMU가해줌(PAGE 테이블(DRAM에 있음) 참고)
가상 메모리는 모든 물리적 설계에 매핑 가능
변환해줄때 page number만 고려

Page Table 
각 프로세스는 물리적 메모리에 하나의 페이지 테이블을 가짐
PTE(Page Table Entry(안에 physical page number가 들어있음))

Page Table Structure
배치 정보를 저장(virtual 페이지 번호로 인덱싱된 페이지 테이블 항목 배열)(CPU의 페이지 테이블 레지스터는 물리적 메모리의 페이지 테이블을 가리킴)
만약 페이지가 메모리에 존재하면 PTE는 피지컬 페이지 번호 저장, 다른 상태 비트 더함 / 페이지X면 PTE는 디스크의 스왑 공간 위치를 참조할 수 있음

Mapping Pages to storage
valid 1 => physical page에 원하는 넘버가있다
valid page => 접근유형별 접근 권한(r,w,x) 확인 => 허용되는경우 실제 주소 생성 / 불법접근시 보호오류 발생(protection error)
invalid page => 페이지가 현재 매핑되지 않았으며 page fault 생성 => swap시켜야함(swap후 entry를 새롭게 업데이트)
보호 오류는 종종 프로그램 오류니 프로그램 종료해야함. page fault는 새 프레임을 할당하고, 새 항목을 페이지 테이블에 추가하며, 페이지를 디스크에서 가져와야 함(수백만 클록 사이클필요)

page table 문제
***고정된 크기의 페이지로 인한 내부 단편화(서로 다른 사이즈가 있어 작은공간이 생겨 일정한 사이즈로 만들어졌는데 필요없는 정보가 생김(internal fragmentation(내부 단편화) => 해결:TLB))
***각 데이터 액세스에는 두 번의 메모리 액세스가 필요(1.페이지 테이블 조회 2. 메모리로 부터 데이터 패치)

Improving Access Time
페이지 테이블을 캐시(오버헤드줄이기)하고 로컬리티 활용
TLB => 접근된게 다시 접근될 확률 증가
모든 액세스는 TLB에서 조회(hit(있을경우)는 물리적 프레임번호를 제공, miss(없는경우)는 페이지테이블에서 프레임 참고)
TLB는 보통 캐시보다 작음(높은 연관성이 일반적,캐시 접근과 비슷한 속도,일반 캐시처럼 취급하고 Write-back과 Write-through사용)
